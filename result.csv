Model,Response_Relevance,Context_Retention,Inference_Time_ms,Model_Size_MB,Training_Data_Size_GB,Energy_Consumption_kWh,Topsis Score,Rank
GPT2_Medium_Dialogue,0.8,0.75,95,1500,40,50,0.3279933515441958,5
GPT_Neo_1.3B,0.83,0.8,140,2600,800,75,0.6178453521444011,3
BLOOM_560M,0.82,0.78,120,1100,350,65,0.4379618115981738,4
FLAN_T5_Base,0.85,0.82,100,990,780,60,0.7914857603064321,1
OPT_1.3B,0.84,0.81,145,2500,180,80,0.1787274939652257,6
LaMDA_Style_Model,0.88,0.86,160,2800,1000,90,0.6418572476946823,2
