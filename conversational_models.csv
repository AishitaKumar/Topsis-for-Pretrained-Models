Model,Response_Relevance,Context_Retention,Inference_Time_ms,Model_Size_MB,Training_Data_Size_GB,Energy_Consumption_kWh
GPT2_Medium_Dialogue,0.8,0.75,95,1500,40,50
GPT_Neo_1.3B,0.83,0.8,140,2600,800,75
BLOOM_560M,0.82,0.78,120,1100,350,65
FLAN_T5_Base,0.85,0.82,100,990,780,60
OPT_1.3B,0.84,0.81,145,2500,180,80
LaMDA_Style_Model,0.88,0.86,160,2800,1000,90
